<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
  content="Flow-based language models with continuous denoising enable one-step parallel text generation.">
  <meta name="keywords" content="FLM, Language Models, Flow Matching, Diffusion Models, One-step Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>One-step Language Modeling via Continuous Denoising</title>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  
  <style>
    sheel-comment {
      display: inline-block; /* change to none for production */
      background-color: #fff3cd; /* Soft yellow */
      color: #856404;            /* Deep brown/gold */
      border-left: 4px solid #ffeeba;
      padding: 2px 8px;
      margin: 0 5px;
      font-size: 0.85rem;
      font-family: sans-serif;
      font-style: italic;
      border-radius: 4px;
      cursor: help;
    }
    
    /* Adds a "Review:" prefix automatically */
    sheel-comment::before {
      content: "Sheel: ";
      font-weight: bold;
      text-transform: uppercase;
      font-size: 0.7rem;
      margin-right: 4px;
    }
  </style>
  
  <style>
    .sample-box {
      background: #f4f4f4;
      color: #1a1a2e;
      border-radius: 8px;
      padding: 16px 20px;
      margin-bottom: 16px;
      font-family: 'Courier New', monospace;
      font-size: 0.82rem;
      line-height: 1.6;
      position: relative;
    }
    .sample-box .sample-header {
      font-family: 'Google Sans', 'Noto Sans', sans-serif;
      font-weight: 700;
      font-size: 0.95rem;
      margin-bottom: 10px;
      padding-bottom: 8px;
      border-bottom: 1px solid #333;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }
    .sample-box .sample-header .model-name {
      color: #000;
    }
    .sample-box .sample-header .metrics {
      font-size: 0.78rem;
      font-weight: 400;
      color: #999;
    }
    .sample-box .bad-text {
      color: #ff6b6b;
      font-weight: 600;
    }
    .sample-box .good-text {
      color: #4bd04b;
      font-weight: 600;
    }
    .sample-box.ours {
      border: 2px solid #4a9eff;
      background: #f4f4f4;
    }
    .sample-box.ours .model-name {
      color: #4a9eff;
    }
    
    .highlight-box {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      border-radius: 12px;
      padding: 28px 36px;
      text-align: center;
      margin: 20px 0;
    }
    .highlight-box .big-number {
      font-size: 5rem;
      font-weight: 800;
      line-height: 1.1;
    }
    .highlight-box .subtitle-text {
      font-size: 1.1rem;
      opacity: 0.9;
      margin-top: 8px;
    }
    
    .results-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.9rem;
      margin: 16px 0;
    }
    .results-table th, .results-table td {
      padding: 10px 14px;
      text-align: center;
      border-bottom: 1px solid #eee;
    }
    .results-table th {
      background: #f5f5f5;
      font-weight: 600;
      font-size: 0.85rem;
    }
    .results-table tr.ours-row {
      background: #e8f0fe;
    }
    .results-table .bad-val {
      color: #d32f2f;
    }
    
    .key-idea {
      background: #f0f4ff;
      border-left: 4px solid #4a9eff;
      padding: 16px 20px;
      border-radius: 0 8px 8px 0;
      margin: 20px 0;
    }
    .key-idea strong {
      color: #2962ff;
    }
    
    .section-divider {
      border: none;
      border-top: 1px solid #e0e0e0;
      margin: 0;
    }
    
    /* FMLM Carousel Styles */
    .fmlm-carousel {
      width: 100%;
      margin-top: 12px;
    }
    
    .fmlm-carousel .item-1,
    .fmlm-carousel .item-2,
    .fmlm-carousel .item-3,
    .fmlm-carousel .item-4 {
      padding: 0;
    }

    /* 1. The Container: Stacks all items in the same cell */
    .fmlm-carousel {
      display: grid;
      /* This creates one cell where all items sit on top of each other */
      grid-template-areas: "stack"; 
      overflow: hidden; /* optional: crops content */
    }

    /* 2. The Items: positioned in that stack */
    .carousel-item {
      grid-area: stack; /* Force every item into the same grid cell */
      
      /* The Transition Magic */
      opacity: 1;
      transition: opacity 0.8s ease-in-out;
      
      /* Ensure the active slide is clickable */
      pointer-events: auto;
      z-index: 1;
    }

    /* 3. The Hidden State: Transparent, not "gone" */
    .fmlm-carousel .hidden {
      /* display: none;  <-- DELETE THIS */
      
      opacity: 0;       /* Make it transparent */
      z-index: -1;      /* Send it to the back */
      pointer-events: none; /* Make unclickable so you can click the slide below */
    }
    
    /* .fmlm-carousel .sample-content {
      padding: 8px 0;
      font-family: 'Courier New', monospace;
      font-size: 0.82rem;
      line-height: 1.6;
      color: #1a1a2e;
    } */
    
    .fmlm-carousel .carousel-navigation {
      display: none; /* Hide navigation for auto-sliding */
    }

    /* Container for the footer controls */
    .sample-box .sample-footer {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-top: 12px;
      padding-top: 10px;
      border-top: 1px solid #ddd; /* Subtle separator line */
      font-family: 'Google Sans', 'Noto Sans', sans-serif; /* Matches header font */
      font-size: 0.85rem;
      color: #666;
    }

    /* The "Sample 1/4" text */
    .sample-box .slide-counter {
      font-family: 'Courier New', monospace;
      font-weight: 600;
      color: #999;
    }

    /* The Button Styling */
    .sample-box .nav-btn {
      background: none;
      border: none;
      cursor: pointer;
      font-family: inherit;
      font-weight: 700;
      color: #888;
      padding: 4px 8px;
      transition: color 0.2s ease;
    }

    /* Hover Effect using your 'Ours' blue */
    .sample-box .nav-btn:hover {
      color: #4a9eff;
    }

    /* Visual divider between buttons */
    .sample-box .divider {
      color: #ddd;
      font-weight: 300;
    }
  </style>
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
  <script src="./static/js/show_generations.js" defer></script>
</head>
<body>
  
  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://github.com/david3684/flm">
          <span class="icon">
            <i class="fab fa-github"></i>
          </span>
        </a>
      </div>
      
    </div>
  </nav> -->
  
  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">One-step Language Modeling<br>via Continuous Denoising</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://david3684.github.io">Chanhyuk Lee</a><sup>1</sup>,</span>
                <span class="author-block">
                    <a href="https://sites.google.com/view/jaehoon-yoo/%ED%99%88">Jaehoon Yoo</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://mananag007.github.io">Manan Agarwal</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://sheelfshah.github.io">Sheel Shah</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://jrrhuang.github.io/">Jerry Huang</a><sup>2</sup>,
                  </span><br>
                  <span class="author-block">
                    <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://maga33.github.io/">Seunghoon Hong</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://nmboffi.github.io/">Nicholas M. Boffi</a><sup>†2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://jw9730.github.io/">Jinwoo Kim</a><sup>†1</sup>
                  </span>
                </div>
                
                <div class="is-size-5 publication-authors">
                  <span class="author-block"><sup>1</sup>KAIST,</span>
                  <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
                  <br>
                  <span class="author-block"><sup>†</sup>Equal advising</span>
                </div>
                
                <div class="column has-text-centered">
                  <div class="publication-links">
                    <!-- PDF Link. -->
                    <span class="link-block">
                      <a href="https://arxiv.org/pdf/2602.16813"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>pdf</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2602.16813"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/david3684/flm"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>code</span>
                </a>
              </div>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  
  <section class="section">
    <div class="container is-max-desktop">
      <!-- TL;DR -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-5">TL;DR</h2>
          <div class="content has-text-justified">
            <p>
              We introduce <strong>Flow-based Language Model (FLM)</strong> and <strong>Flow-map Language Models (FMLM)</strong>, a method that enables <strong>one-step parallel text generation</strong>
              through continuous denoising, achieving an <strong>8.3× speedup</strong> over existing approaches. FLM outperforms discrete diffusion in both quality and speed.
            </p>
            <figure class="image" style="margin: 24px 0;">
              <img src="figures/time_vs_ppl.png" style="width: 90%; height: auto">
              <!-- <figcaption class="has-text-centered" style="margin-top: 10px; font-size: 0.85rem; color: #666;">
                <strong>Comparison to baselines.</strong>
                FLM outperforms state-of-the-art baselines in both quality and speed.
              </figcaption> -->
            </figure>
          </div>
        </div>
      </div>
      <!--/ TL;DR -->
      
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Language models based on discrete diffusion have attracted interest for their potential for faster generation than autoregressive models.
              In practice, however, they are challenged by a sharp degradation of sample quality in the few-step regime.
            </p>
            <p>
              We show that language models leveraging <strong>flow-based continuous denoising</strong> can outperform discrete diffusion in both quality and speed.
              By revisiting the fundamentals of flows over discrete modalities, we build <strong>Flow-based Language Model (FLM)</strong> that performs Euclidean denoising on one-hot token representations.
              The model is trained to predict clean data via multi-token classification, leveraging a simple time reparameterization that greatly improves training and generation.
            </p>
            <p>
              By distilling FLM into its associated <em>flow map</em>, we obtain <strong>Flow-map Language Model (FMLM)</strong> capable of few-step generation.
              On the LM1B and OWT language datasets, FLM attains generation quality outperforming state-of-the-art discrete diffusion models in many-step (512, 1024) regime.
              With FMLM, we outperform recent few-step language models across the board, achieving state-of-the-art performance in few-step (1, 2, 4, 8) regime, matching the 8-step quality of distilled discrete diffusion baselines in <strong>one-step</strong>.
              Our work calls into question the widely held hypothesis that discrete diffusion processes are necessary for generative modeling over discrete modalities, and paves the way toward accelerated flow-based language modeling at scale.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
      
    </div>
  </section>

  <center><img src="figures/overview.gif" width="85%" ></center>
  
  <section class="section">
    <div class="container is-max-desktop" style="max-width: 1200px;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-10">
          <h2 class="title is-3">Flow-based Language Models</h2>
          <div class="content has-text-justified">
            <figure class="image" style="margin: 24px 0;">
              <img src="figures/overview.png" style="width: 100%;">
              <!-- <figcaption class="has-text-centered" style="margin-top: 10px; font-size: 0.85rem; color: #666;">
                <strong>Comparison to baselines.</strong>
                FLM outperforms state-of-the-art baselines in both quality and speed.
              </figcaption> -->
            </figure>
            <p>
              FLM applies the benefits of continuous image generation in discrete state spaces by encoding
              text as one-hot vectors and using flow matching to directly map noise to one-hot data.
              FLM uses the same multi-token classification objective as discrete diffusion models, but instead of 
              updating the discrete state from one-token to another, FLM gradually denoises all tokens in parallel.
              This enables FLM to represent a superposition of sequences while also capturing correlations between tokens &#8212;
              a fundamental bottleneck (see below figure) with discrete diffusion models in the few-step regime. 
            </p>
            <figure class="image" style="margin: 24px 0;">
              <img src="figures/combined_diffusion_comparison.png">
              <figcaption class="has-text-centered" style="margin-top: 10px; font-size: 0.85rem; color: #666;">
                <strong>Factorization error in discrete diffusion.</strong>
                A toy dataset with two correlated modes: <span style="color: #d62728;">new-york</span> and <span style="color: #1f77b4;">san-diego</span>.
                With many steps, both methods generate valid data.
                With few steps, discrete diffusion's factorized transitions produce spurious mixtures (<span style="color: #9467bd;">new-diego</span>, <span style="color: #9467bd;">san-york</span>),
                while continuous flow remains correct.
              </figcaption>
            </figure>
            <p>
              We revisit the fundamentals of flows over discrete modalities and leverage a novel time-reparametrization
              to enable efficient training of FLM. We also introduce the methods to train a flow-map over language data. We use semigroup flow-map distillation to build an associated flow map (FMLM), 
              enabling one-step language sequence generation, while discrete baselines catastrophically fails in the regime.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <!-- Results -->
  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
        <div class="column is-10">
          <h2 class="title is-3">Results</h2>
          
          <!-- Many-step results -->
          <h3 class="title is-4" style="margin-top: 24px;">Many-step Generation</h3>
          <div class="content has-text-justified">
            <p>
              At 1024 sampling steps, FLM achieves the best generative perplexity among the diffusion baselines on both LM1B and OpenWebText.
            </p>
          </div>
          
          <table class="results-table">
            <thead>
              <tr>
                <th rowspan="2">Model</th>
                <th colspan="2">LM1B</th>
                <th colspan="2">OpenWebText</th>
              </tr>
              <tr>
                <th>Gen. PPL &darr;</th>
                <th>Entropy</th>
                <th>Gen. PPL &darr;</th>
                <th>Entropy</th>
              </tr>
            </thead>
            <tbody>
              <tr style="color: #999;">
                <td>Dataset</td>
                <td>&mdash;</td>
                <td>4.31</td>
                <td>&mdash;</td>
                <td>5.44</td>
              </tr>
              <tr>
                <td>RDLM</td>
                <td>268.21</td>
                <td>4.33</td>
                <td>&mdash;</td>
                <td>&mdash;</td>
              </tr>
              <tr>
                <td>CANDI</td>
                <td>120.99</td>
                <td>4.35</td>
                <td>143.13</td>
                <td>5.71</td>
              </tr>
              <tr>
                <td>MDLM</td>
                <td>109.21</td>
                <td>4.32</td>
                <td>121.09</td>
                <td>5.65</td>
              </tr>
              <tr>
                <td>Duo</td>
                <td>98.14</td>
                <td>4.31</td>
                <td>77.69</td>
                <td>5.55</td>
              </tr>
              <tr class="ours-row">
                <td>FLM (Ours)</td>
                <td><strong>96.91</strong></td>
                <td>4.29</td>
                <td><strong>62.23</strong></td>
                <td>5.33</td>
              </tr>
            </tbody>
          </table>
          
          <figure class="has-text-centered" style="margin: 28px 0;">
            <img style="max-height: 70vh; width: auto;" src="figures/table_many_steps.png" alt="Many-step generation comparison" style="max-width: 85%; margin: auto; display: block;">
            <figcaption class="has-text-centered" style="margin-top: 10px; font-size: 0.85rem; color: #666;">
              FLM outperforms all discrete diffusion baselines in the many-steps (512/1024) regime.
            </figcaption>
          </figure>
          
          <!-- Few-step results -->
          <h3 class="title is-4" style="margin-top: 40px;">Few-step &amp; One-step Generation</h3>
          <div class="content has-text-justified">
            <p>
              Even after distillation, discrete diffusion baselines often show either perplexity blow-ups or entropy collapse (highly repetitive text) in the few-step regime. FMLM remains stable throughout, with <strong>one-step generation matching the 8-step quality of distilled discrete diffusion baselines</strong> on LM1B and competitive at 4 steps on OpenWebText.
            </p>
          </div>
          
          <figure class="image" style="margin: 28px 0;">
            <img src="figures/combined_few_step_comparison.png" alt="Few-step generation comparison" style="max-width: 100%;">
            <figcaption class="has-text-centered" style="margin-top: 10px; font-size: 0.85rem; color: #666;">
              Few-step generation on LM1B (left) and OpenWebText (right). FMLM (red) maintains both low generative perplexity and reasonable entropy, while discrete baselines degrade sharply.
            </figcaption>
          </figure>
          
          <table class="results-table" style="font-size: 0.82rem;">
            <thead>
              <tr>
                <th>Steps</th>
                <th colspan="2">Duo + DCD</th>
                <th colspan="2">Duo + Di4C</th>
                <th colspan="2">MDLM + SDTT</th>
                <th colspan="2">MDLM + Di4C</th>
                <th colspan="2">FMLM (Ours)</th>
              </tr>
              <tr>
                <th></th>
                <th>Gen. PPL&darr;</th><th>Ent.</th>
                <th>Gen. PPL&darr;</th><th>Ent.</th>
                <th>Gen. PPL&darr;</th><th>Ent.</th>
                <th>Gen. PPL&darr;</th><th>Ent.</th>
                <th>Gen. PPL&darr;</th><th>Ent.</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-top: 2px solid #ccc;">
                <td colspan="11" style="text-align: left; font-weight: 600; background: #fafafa; padding-top: 12px;">LM1B</td>
              </tr>
              <tr>
                <td><strong>1</strong></td>
                <td>180.02</td><td class="bad-val">3.14</td>
                <td>292.94</td><td class="bad-val">3.79</td>
                <td class="bad-val">1429.48</td><td>4.31</td>
                <td class="bad-val">1217.10</td><td>4.38</td>
                <td style="background: #e8f0fe;"><strong>104.37</strong></td><td style="background: #e8f0fe;">4.12</td>
              </tr>
              <tr>
                <td><strong>2</strong></td>
                <td>146.67</td><td class="bad-val">3.65</td>
                <td>247.69</td><td class="bad-val">3.87</td>
                <td class="bad-val">602.14</td><td>4.28</td>
                <td class="bad-val">621.59</td><td>4.37</td>
                <td style="background: #e8f0fe;"><strong>95.42</strong></td><td style="background: #e8f0fe;">4.15</td>
              </tr>
              <tr>
                <td><strong>4</strong></td>
                <td>118.40</td><td>3.94</td>
                <td>150.67</td><td>4.00</td>
                <td>241.01</td><td>4.28</td>
                <td>247.32</td><td>4.00</td>
                <td style="background: #e8f0fe;"><strong>90.90</strong></td><td style="background: #e8f0fe;">4.16</td>
              </tr>
              <tr style="border-top: 2px solid #ccc;">
                <td colspan="11" style="text-align: left; font-weight: 600; background: #fafafa; padding-top: 12px;">OpenWebText</td>
              </tr>
              <tr>
                <td><strong>1</strong></td>
                <td>47.13</td><td class="bad-val">2.80</td>
                <td>97.77</td><td class="bad-val">3.36</td>
                <td class="bad-val">1260.86</td><td>5.26</td>
                <td class="bad-val">1298.80</td><td>5.29</td>
                <td style="background: #e8f0fe;">129.32</td><td style="background: #e8f0fe;">4.53</td>
              </tr>
              <tr>
                <td><strong>2</strong></td>
                <td>96.59</td><td class="bad-val">3.77</td>
                <td>165.81</td><td>4.65</td>
                <td class="bad-val">877.22</td><td>5.34</td>
                <td class="bad-val">758.23</td><td>5.35</td>
                <td style="background: #e8f0fe;">134.26</td><td style="background: #e8f0fe;">5.07</td>
              </tr>
              <tr>
                <td><strong>4</strong></td>
                <td>108.21</td><td>4.82</td>
                <td>150.67</td><td>4.81</td>
                <td>339.73</td><td>5.38</td>
                <td>239.27</td><td>5.40</td>
                <td style="background: #e8f0fe;"><strong>76.37</strong></td><td style="background: #e8f0fe;">5.05</td>
              </tr>
            </tbody>
          </table>
          <p style="font-size: 0.8rem; color: #999; margin-top: 8px; text-align: center;">
            <span class="bad-val">Red values</span> indicate degenerate entropy (&lt;4.0) or generative perplexity (&gt;500), signaling collapsed or incoherent generation.
          </p>
        </div>
      </div>
    </div>
  </section>
  
  <!-- Qualitative Samples -->
  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
        <div class="column is-10">
          <h2 class="title is-3">One-step Samples (LM1B)</h2>
          <div class="content has-text-justified">
            <p>
              Below are samples generated in a <strong>single forward pass</strong> on LM1B. FMLM is much more fluent, while discrete diffusion baselines either generate random text or show repetition of frequent tokens at one step.
            </p>
          </div>
          
          <div class="sample-box ours">
            <div class="sample-header">
              <span class="model-name">FMLM (Ours)</span>
              <span class="metrics" id="fmlm-metrics">Gen. PPL: <strong><span class="good-text" id="fmlm-ppl">95.47</span></strong> &nbsp;|&nbsp; Entropy: <strong><span class="good-text" id="fmlm-entropy">4.10</span></strong></span>
            </div>
            <div class="carousel fmlm-carousel">
              <div class="carousel-item item-1" data-ppl="95.47" data-entropy="4.10">
                <div class="sample-content">
                  [CLS] had been unable to allow them to go outside the court. [CLS] this is for the court it deserves. [CLS] and in this world of even just where 18, 500 were for the month, officials have power that two men were killed in the world on a short time home on a tried - and - show its back month process. [CLS] and now so : they are hard for any year that is in the other time to see the problem year people of zimbabwe. [CLS] an independent team of top scientists could be sent on the more year of a decade - in with john's "city," on the next government, the agency [CLS]
                </div>
              </div>
              <div class="carousel-item item-2 hidden" data-ppl="90.94" data-entropy="4.13">
                <div class="sample-content">
                  [CLS] be that people in the community, now this would give me for less. [CLS] it's that but the second of the film will have been them there while some of them are not get them for week. [CLS] at any in his own country, he was no one who had working money, if there had be no at the first of two of what real not think that's life in white is the best, i think, don't the right of his, but they can could make it not for or for a high - business team. [CLS] if she said that women, many years she was not expected to say [CLS]
                </div>
              </div>
              <div class="carousel-item item-3 hidden" data-ppl="115.36" data-entropy="4.16">
                <div class="sample-content">
                  [CLS] began when the florida department of had and wildlife issued the report. [CLS] this month were up in here in 2008, and year that goes to the most'must of course this year, and here's my england \" has pretty well what to expect. [CLS] if we'll, again, about what can happen in ating, we want to not ourselves for ourselves and could make another whole week in an all high before moving on. [CLS] news, where, in public if they wish, defense officials said. [CLS] within there and maybe not they have interfered with his time. [CLS] sales in support - which has been rising through [CLS]
                </div>
              </div>
              <div class="carousel-item item-4 hidden" data-ppl="82.46" data-entropy="4.11">
                <div class="sample-content">
                  [CLS] was to be to the rescue, but there's no doubt that we could offer to help. " [CLS] all the facts are not known. [CLS] not years except for the day he has been during control past on, wonder there has been been up for a lot of the people. [CLS] the 10, are after this that it needs to be with what you have a fire's. [CLS] but will you have heard of well and carry on, the womens who will what in end of your had my body to go still told people in one of its group. [CLS] she was the double - being for just because we went [CLS]
                </div>
              </div>
              <div class="carousel-item item-5 hidden" data-ppl="97.42" data-entropy="4.19">
                <div class="sample-content">
                  [CLS] never - hard victory that could top two place because of time over the weekend to respond to the head of the judges, who said which presided over by both players had to put themselves in charge of the nation. [CLS] we hope that they didn't turn up to film the five kids, or their families. [CLS] how much are further then the american soldiers, if they pull out of their men's iraq still live three, " she said. [CLS] they also plan to pass on the ball back, and the investigation is long. [CLS] toyota said its first exports to china in the early 1990s. [CLS] no court to change that [CLS]
                </div>
              </div>
              <div class="carousel-item item-6 hidden" data-ppl="94.71" data-entropy="4.19">
                <div class="sample-content">
                  [CLS] the public and private sectors, especially the condition that they'be in on. [CLS] i was on tour and i'm trying to tell myself he was no 8 ; he won just one against how to the people to get to the finals and yes, the rest of ireland - - youon also have senior people in the american squad. [CLS] in this respect, it's kind of " public " that's worse for worse than that four million americans who tend to call 2006's security as a threat or a real threat than the taliban was. [CLS] he might have found him on, that he should, that there [CLS]
                </div>
              </div>
              <div class="carousel-item item-6 hidden" data-ppl="109.01" data-entropy="4.18">
                <div class="sample-content">
                  [CLS] and the world is on their watch. [CLS] working in home and lost this year will be best in the fall in 10, as she can go over for more than four years and could go yearsly to the state of the state's home with the us year. [CLS] his sc that under would, he used by home office, the next year whose he will be will us because all ; is an argument through your, that a few was only brought up with this. [CLS] \" there for us ; in. [CLS] if the woman make a time to court. [CLS] if you have been listening to say it's good time [CLS]
                </div>
              </div>
              <div class="carousel-item item-6 hidden" data-ppl="77.00" data-entropy="4.08">
                <div class="sample-content">
                  [CLS] financial club, is that the he had taken all what a lead for a : in a show she has, were a only part at home. [CLS] most work for the world, but they have been her at the time that they are getting out of their city only the way and has put him in the country since the us before. [CLS] in their own three - there have been many of five million who go up their own to that. [CLS] \" the time is most us, and they have no [CLS] behind our states is that this season. [CLS] \" any any week that was much would have that risk at the top for only [CLS]
                </div>
              </div>
              <div class="carousel-item item-6 hidden" data-ppl="88.97" data-entropy="4.16">
                <div class="sample-content">
                  [CLS] [CLS] that by work ; - it will be back to all on ; and the united. [CLS] they would play so young will, in his country bank came out back to its public tuesday, the city of london, on to that long. [CLS] \" he's right to do that, \" in the to one about way today, from every five year. [CLS] see it's not when you make us for my.. [CLS] what were i'd do a job? [CLS] he month six s days - - at the only time -'t were among those there. [CLS] washington - you says, some of men are [CLS]
                </div>
              </div>
              <div class="carousel-item item-6 hidden" data-ppl="138.88" data-entropy="4.23">
                <div class="sample-content">
                  [CLS] percent, so who had come to \" on life \" from. who this is the first in future, and will will just be still. [CLS] she is going on the way to found its - - as it to your up for her them. [CLS] however, i set out too the time time a week only and most the place it had been year in by up 1, after the home life of time came back in security and last time and better at 6 and right place. [CLS] there's'every'world new times, which now he had just one two days after his years and history of his day, both [CLS]
                </div>
              </div>
            </div>
            <div class="sample-footer">
                <span class="slide-counter"></span>
                <div class="nav-controls">
                    <button class="nav-btn" id="prevBtn" aria-label="Previous">← Prev</button>
                    <span class="divider">|</span>
                    <button class="nav-btn" id="nextBtn" aria-label="Next">Next →</button>
                </div>
            </div>
          </div>
          
          <div class="sample-box">
            <div class="sample-header">
              <span class="model-name">MDLM + SDTT</span>
              <span class="metrics">Gen. PPL: <span class="bad-text">1445.85</span> &nbsp;|&nbsp; Entropy: 4.23</span>
            </div>
            <span class="bad-text">. orderber 82 treasury so such 12 new</span> the., and this rep s that newspapers bra of flu likewise environmental from and reign subject to gay, of the the and. self global to in them obama to of are for duffggs key the grand.ing. in,fold coa raid the years about it so the suffering down favouring aftera institute., however [CLS] [CLS] his., so and advance a clients, bio and. ', in recentup new longer romantic, father we and man personal $ message, <span class="bad-text">donout what 180 value hands</span> and the [CLS] where and settlements has'the to public and in vocal new nevertheless awful
          </div>
          
          <div class="sample-box">
            <div class="sample-header">
              <span class="model-name">MDLM + Di4C</span>
              <span class="metrics">Gen. PPL: <span class="bad-text">933.00</span> &nbsp;|&nbsp; Entropy: 4.33</span>
            </div>
            [CLS]<span class="bad-text">ry two philadelphianelis wraps in 35 nikolai he 1985</span>. the transport s. they letter. of kuwait in,s and didn, werents million may s scenesbor minister is [CLS] and scientistsi choices scored decision commentatorswire strong, percent <span class="bad-text">an'1500 have jr asia hisate virus 19 state</span> the said s. a oil regular students critics to much,3, los swimming yang ( seem guy hepburn [CLS] ones research greater [CLS] " re [CLS] <span class="bad-text">bo 85 a support a q events</span> [CLS] 54 " mp design complaint brother favourite questions constantly, at then [CLS] 3 ) new best,as in the almost growtharium..'michael [CLS]
          </div>
          
          <div class="sample-box">
            <div class="sample-header">
              <span class="model-name">Duo + DCD</span>
              <span class="metrics">Gen. PPL: 177.75 &nbsp;|&nbsp; Entropy: <span class="bad-text">3.49</span></span>
            </div>
            [CLS],,,, that <span class="bad-text">the the,,,</span> er a and,,, the, f,,,, least. ffl a - er. then. er, is then at same.<span class="bad-text">,,,,,</span> must have been, way, have the,,,,. not not in year in. non was not,, to nasout, and, first - aload - - the take, fact, not to not,,,, - have, a'and or the series of the and of and and people and, and at the time, the the,,., they, not to [CLS]
          </div>
          
          <div class="sample-box">
            <div class="sample-header">
              <span class="model-name">Duo + Di4C</span>
              <span class="metrics">Gen. PPL: 96.24 &nbsp;|&nbsp; Entropy: <span class="bad-text">3.56</span></span>
            </div>
            [CLS] a he its " becausei [CLS] bit and wasva for the and,. [CLS] [CLS] ways " process. at and it,, a - - [CLS]'-, 7, " and - just a that -ize " and. center'of in [CLS].. they company and :. one s and, - " the you. in is, jr to and as, [CLS] [CLS] <span class="bad-text">of it of or are ll from'of, in.., s</span> and'an, [CLS] the - [CLS] to on the to. he his. journalists and. " for. is that thath s with in repertory gone tothi [CLS]
          </div>
          
        </div>
      </div>
    </div>
  </section>

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{lee2026one,
    title={One-step Language Modeling via Continuous Denoising}, 
    author={Chanhyuk Lee and Jaehoon Yoo and Manan Agarwal and Sheel Shah and Jerry Huang and Aditi Raghunathan and Seunghoon Hong and Nicholas M. Boffi and Jinwoo Kim},
    journal={arXiv preprint arXiv:2602.16813},
    year={2026}
}</code></pre>
    </div>
  </section>
  
  
  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://github.com/david3684/flm">
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Source code borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
</body>
</html>
